{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  okay i\\u2019m sorry but taylor swift looks not...  negative\n",
      "1  @user the dc comics site has batman 44 release...   neutral\n",
      "2  \"frank gaffrey\\u002c cliff may\\u002c steve eme...  positive\n",
      "3  the tragedy of only thinking up hilarious twee...  negative\n",
      "4  \"oliseh meets with victor moses in london: sup...   neutral\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"review_data.csv\")\n",
    "data=data[[\"text\",\"label\"]]\n",
    "\n",
    "\n",
    "data[\"text\"]=data[\"text\"].str.lower()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>okay i\\u2019m sorry but taylor swift looks not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"frank gaffrey\\u002c cliff may\\u002c steve eme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the tragedy of only thinking up hilarious twee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"people always forget the fact that shawn achi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it looks like a beautiful night to throw mysel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  okay i\\u2019m sorry but taylor swift looks not...      0\n",
       "2  \"frank gaffrey\\u002c cliff may\\u002c steve eme...      1\n",
       "3  the tragedy of only thinking up hilarious twee...      0\n",
       "5  \"people always forget the fact that shawn achi...      1\n",
       "6  it looks like a beautiful night to throw mysel...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data=data[data[\"label\"]!=\"neutral\"]\n",
    "\n",
    "data[\"label\"] = np.where(data[\"label\"] == \"positive\", 1,0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##word to vectors\n",
    "\n",
    "\n",
    "-tokenization\n",
    "-remove stopwords ,punctuation marks,specialcharecters\n",
    "-stemming,lemmatization\n",
    "\n",
    "techniques:\n",
    "-bow(countVectorizer)\n",
    "-tfidf\n",
    "-word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    okay u2019m sorry taylor swift look nothing li...\n",
       "2    frank gaffrey u002c cliff may u002c steve emer...\n",
       "3    tragedy thinking hilarious tweet summer olympi...\n",
       "5    people always forget fact shawn achieved much ...\n",
       "6    look like beautiful night throw brooklyn bridg...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lemma=WordNetLemmatizer()\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text):\n",
    "  text=text.lower()\n",
    "  text=re.sub(r\"[^a-zA-Z0-9]\",\" \",text)\n",
    "  words=nltk.word_tokenize(text) \n",
    "  return \" \".join([lemma.lemmatize(word) for word in words if word not in stop_words])\n",
    "\n",
    "\n",
    "\n",
    "data[\"text\"]=data[\"text\"].apply(lambda x:clean_text(x))\n",
    "data[\"text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,r2_score,confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009,)\n",
      "(433,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(data[\"text\"],data[\"label\"],test_size=0.3,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x_train_vector,x_test_vector,y_train,y_test):\n",
    "\n",
    "  models={\"naivebayes\":MultinomialNB(),\n",
    "        \"logisticregression\":LogisticRegression(),\n",
    "        \"svm\":SVC(),\"decisiontree\":DecisionTreeClassifier(),\n",
    "        \"randomforest\":RandomForestClassifier(),\n",
    "        \"knn\":KNeighborsClassifier()\n",
    "        }\n",
    "\n",
    "  for name,model in models.items():\n",
    "     \n",
    "    model.fit(x_train_vector,y_train)\n",
    "    y_test_pred = model.predict(x_test_vector)\n",
    "    test_model_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print(name+\":\")\n",
    "    print(\"r2 score:\",test_model_score)\n",
    "    print(confusion_matrix(y_test,y_test_pred))\n",
    "    print(classification_report(y_test,y_test_pred))\n",
    "    print(\"-----------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer countVectorizer :::\n",
      "naivebayes:\n",
      "r2 score: -0.21068470929736227\n",
      "[[142  70]\n",
      " [ 61 160]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       212\n",
      "           1       0.70      0.72      0.71       221\n",
      "\n",
      "    accuracy                           0.70       433\n",
      "   macro avg       0.70      0.70      0.70       433\n",
      "weighted avg       0.70      0.70      0.70       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "logisticregression:\n",
      "r2 score: -0.30310338939639747\n",
      "[[144  68]\n",
      " [ 73 148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67       212\n",
      "           1       0.69      0.67      0.68       221\n",
      "\n",
      "    accuracy                           0.67       433\n",
      "   macro avg       0.67      0.67      0.67       433\n",
      "weighted avg       0.67      0.67      0.67       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "svm:\n",
      "r2 score: -0.34931272944591507\n",
      "[[145  67]\n",
      " [ 79 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67       212\n",
      "           1       0.68      0.64      0.66       221\n",
      "\n",
      "    accuracy                           0.66       433\n",
      "   macro avg       0.66      0.66      0.66       433\n",
      "weighted avg       0.66      0.66      0.66       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "decisiontree:\n",
      "r2 score: -0.6820199778024421\n",
      "[[129  83]\n",
      " [ 99 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59       212\n",
      "           1       0.60      0.55      0.57       221\n",
      "\n",
      "    accuracy                           0.58       433\n",
      "   macro avg       0.58      0.58      0.58       433\n",
      "weighted avg       0.58      0.58      0.58       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "randomforest:\n",
      "r2 score: -0.3400708614360115\n",
      "[[156  56]\n",
      " [ 89 132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.68       212\n",
      "           1       0.70      0.60      0.65       221\n",
      "\n",
      "    accuracy                           0.67       433\n",
      "   macro avg       0.67      0.67      0.66       433\n",
      "weighted avg       0.67      0.67      0.66       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "knn:\n",
      "r2 score: -0.8391317339708022\n",
      "[[179  33]\n",
      " [166  55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.84      0.64       212\n",
      "           1       0.62      0.25      0.36       221\n",
      "\n",
      "    accuracy                           0.54       433\n",
      "   macro avg       0.57      0.55      0.50       433\n",
      "weighted avg       0.57      0.54      0.50       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "vectorizer tfidf :::\n",
      "naivebayes:\n",
      "r2 score: -0.4417314095449505\n",
      "[[136  76]\n",
      " [ 80 141]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64       212\n",
      "           1       0.65      0.64      0.64       221\n",
      "\n",
      "    accuracy                           0.64       433\n",
      "   macro avg       0.64      0.64      0.64       433\n",
      "weighted avg       0.64      0.64      0.64       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "logisticregression:\n",
      "r2 score: -0.40476393750533624\n",
      "[[137  75]\n",
      " [ 77 144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64       212\n",
      "           1       0.66      0.65      0.65       221\n",
      "\n",
      "    accuracy                           0.65       433\n",
      "   macro avg       0.65      0.65      0.65       433\n",
      "weighted avg       0.65      0.65      0.65       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "svm:\n",
      "r2 score: -0.38628020148552933\n",
      "[[144  68]\n",
      " [ 82 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       212\n",
      "           1       0.67      0.63      0.65       221\n",
      "\n",
      "    accuracy                           0.65       433\n",
      "   macro avg       0.65      0.65      0.65       433\n",
      "weighted avg       0.65      0.65      0.65       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "decisiontree:\n",
      "r2 score: -0.6265687697430209\n",
      "[[149  63]\n",
      " [113 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.70      0.63       212\n",
      "           1       0.63      0.49      0.55       221\n",
      "\n",
      "    accuracy                           0.59       433\n",
      "   macro avg       0.60      0.60      0.59       433\n",
      "weighted avg       0.60      0.59      0.59       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "randomforest:\n",
      "r2 score: -0.5341500896439857\n",
      "[[135  77]\n",
      " [ 89 132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62       212\n",
      "           1       0.63      0.60      0.61       221\n",
      "\n",
      "    accuracy                           0.62       433\n",
      "   macro avg       0.62      0.62      0.62       433\n",
      "weighted avg       0.62      0.62      0.62       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "knn:\n",
      "r2 score: -0.6542943737727316\n",
      "[[140  72]\n",
      " [107 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.66      0.61       212\n",
      "           1       0.61      0.52      0.56       221\n",
      "\n",
      "    accuracy                           0.59       433\n",
      "   macro avg       0.59      0.59      0.59       433\n",
      "weighted avg       0.59      0.59      0.58       433\n",
      "\n",
      "-----------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "convert_vectors={\"countVectorizer\":CountVectorizer(max_features=500, binary=False ),\"tfidf\":TfidfVectorizer(max_features=100,ngram_range=(1,3))}\n",
    "\n",
    "\n",
    "\n",
    "for name,vector in convert_vectors.items():\n",
    "  print(\"vectorizer\",name,\":::\")\n",
    "  vectorizer=vector\n",
    "  x_train_vector=vectorizer.fit_transform(x_train).toarray()\n",
    "  x_test_vector=vectorizer.transform(x_test).toarray()\n",
    "  training(x_train_vector,x_test_vector,y_train,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
